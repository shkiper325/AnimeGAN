{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import tensorflow.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tensorpack import dataflow\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nets import G, D\n",
    "from parameters import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "\n",
    "if USE_CUDA:\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    print('Can\\'t find DATA_PATH:', DATA_PATH) \n",
    "    quit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_SIZE == 0:\n",
    "    print('No dataset found')\n",
    "    quit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_iter():\n",
    "    filenames = os.listdir(DATA_PATH)\n",
    "    \n",
    "    while True:\n",
    "        random.shuffle(filenames)\n",
    "        \n",
    "        for fn in filenames:\n",
    "            yield os.path.join(DATA_PATH, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    if image.shape[0] != 64 or image.shape[1] != 64 or image.shape[2] != 3:\n",
    "        print('Bad image shape')\n",
    "        quit(1)\n",
    "    \n",
    "    image = np.moveaxis(image, 2, 0)\n",
    "    image = ((image / 255.) - .5) * 2\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_iter = dataflow.MapData(path_iter(), func=prepare_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 64\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(PRIOR_DIM, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.cuda()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (-1, PRIOR_DIM, 1, 1))\n",
    "        \n",
    "        x = self.main(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        \n",
    "        return x.view((-1, 1))\n",
    "    \n",
    "    def clip(self):\n",
    "        self.main[0].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[2].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[4].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[6].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[8].weight.data.clamp_(min=-CLIP, max=CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) in [nn.Conv2d, nn.Linear, nn.ConvTranspose2d]:\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0, std=INIT_STD)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.normal_(m.bias.data, mean=0, std=INIT_STD)\n",
    "    elif type(m) in [nn.BatchNorm2d, nn.LeakyReLU, nn.ReLU, nn.Sequential, nn.Tanh]:\n",
    "        return\n",
    "    else:\n",
    "        print('Couldn\\'t init wieghts of layer with type:', type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't init wieghts of layer with type: <class '__main__.G'>\n",
      "Couldn't init wieghts of layer with type: <class 'torch.nn.modules.activation.Sigmoid'>\n",
      "Couldn't init wieghts of layer with type: <class '__main__.D'>\n"
     ]
    }
   ],
   "source": [
    "generator = G()\n",
    "discriminator = D()\n",
    "\n",
    "generator.apply(init_weights)\n",
    "discriminator.apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optim = optim.RMSprop(generator.parameters(), lr = LR)\n",
    "D_optim = optim.RMSprop(discriminator.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior():\n",
    "    #return np.random.multivariate_normal(np.zeros(PRIOR_DIM), np.identity(PRIOR_DIM))\n",
    "    return np.random.randn(PRIOR_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_minibatch():\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for image in image_iter:\n",
    "        ret.append(image)\n",
    "        \n",
    "        i += 1\n",
    "        if i == MINIBATCH_SIZE:\n",
    "            break\n",
    "    \n",
    "    return np.stack(ret, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fn=None, epoch_num=None):\n",
    "    if fn is None:\n",
    "        fn = 'checkpoint'\n",
    "\n",
    "    torch.save({\n",
    "        'gen': generator.state_dict(),\n",
    "        'dis': discriminator.state_dict(),\n",
    "        'g_opt': G_optim.state_dict(),\n",
    "        'd_opt': D_optim.state_dict(),\n",
    "        'last_epoch' : epoch_num\n",
    "    }, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fn):\n",
    "    if fn is None:\n",
    "        fn = 'checkpoint'\n",
    "    state = torch.load(fn)\n",
    "\n",
    "    generator.load_state_dict(state['gen'])\n",
    "    discriminator.load_state_dict(state['dis'])\n",
    "    G_optim.load_state_dict(state['g_opt'])\n",
    "    D_optim.load_state_dict(state['d_opt'])\n",
    "    \n",
    "    if not(state['last_epoch'] is None):\n",
    "        start_epoch = state['last_epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold start\n",
      "===============================\n",
      "Epoch 0 started!\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 19373/19373 [1:56:25<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "===============================\n",
      "Epoch 1 started!\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 19373/19373 [1:58:11<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "===============================\n",
      "Epoch 2 started!\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 19373/19373 [2:08:14<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "PLOT_FREQ = 100\n",
    "GEN_FREQ = 100\n",
    "\n",
    "if not os.path.exists('generated'):\n",
    "    os.mkdir('generated')\n",
    "    \n",
    "if os.path.exists('checkpoint'):\n",
    "    load('checkpoint')\n",
    "    print('Loaded checkpoint')\n",
    "else:\n",
    "    print('Cold start')    \n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "    \n",
    "plot_iter = 0\n",
    "gen_iter = 0\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "for epoch_num in range(start_epoch, EPOCH_COUNT):\n",
    "    print('===============================')\n",
    "    print('Epoch', epoch_num, 'started!')\n",
    "    print('===============================')\n",
    "    \n",
    "    for t in tqdm(range(EPOCH_LEN)):     \n",
    "        min_d_loss = 1e100\n",
    "        \n",
    "        for k in range(DISCRIMINATOR_LEARNING_REPEATS):\n",
    "            D_optim.zero_grad()\n",
    "            \n",
    "            mean_d_loss = 0\n",
    "\n",
    "            for sample_num in range(BATCH_DIVISOR):\n",
    "                data = FloatTensor(get_data_minibatch())\n",
    "                p = FloatTensor(np.stack([prior() for i in range(MINIBATCH_SIZE)], axis=0))\n",
    "\n",
    "                D_of_x = discriminator(data)\n",
    "                D_of_G_of_z = discriminator(generator(p))\n",
    "\n",
    "                loss = D_of_x - D_of_G_of_z\n",
    "                loss = torch.mean(loss, dim = 0)\n",
    "                loss = -loss\n",
    "                loss = loss / BATCH_DIVISOR\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                mean_d_loss += loss.item()\n",
    "                \n",
    "            D_optim.step()\n",
    "            \n",
    "            discriminator.clip()\n",
    "            \n",
    "            mean_d_loss /= BATCH_DIVISOR\n",
    "            min_d_loss = min(mean_d_loss, min_d_loss)\n",
    "        \n",
    "        #=========================================\n",
    "        \n",
    "        G_optim.zero_grad()\n",
    "\n",
    "        mean_g_loss = 0\n",
    "        \n",
    "        for sample_num in range(BATCH_DIVISOR):\n",
    "            p = FloatTensor(np.stack([prior() for i in range(MINIBATCH_SIZE)], axis=0))\n",
    "\n",
    "            D_of_G_of_z = discriminator(generator(p))\n",
    "\n",
    "            loss = -D_of_G_of_z\n",
    "            loss = torch.mean(loss, dim = 0)\n",
    "            loss = loss / BATCH_DIVISOR\n",
    "\n",
    "            loss.backward()\n",
    "        \n",
    "            mean_g_loss += loss.item()\n",
    "\n",
    "        G_optim.step()\n",
    "        \n",
    "        mean_g_loss /= BATCH_DIVISOR\n",
    "        \n",
    "        #=========================================\n",
    "        \n",
    "        g_losses.append(mean_g_loss)\n",
    "        d_losses.append(mean_d_loss)\n",
    "        \n",
    "        if gen_iter % GEN_FREQ:\n",
    "            generator.eval()        \n",
    "            image = (generator(FloatTensor(np.expand_dims(prior(), 0))).detach().cpu().numpy()[0] + 1) / 2\n",
    "            image = (np.moveaxis(image, 0, 2) * 255).astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join('generated', str(t % 16) + '.jpg'), image)\n",
    "            generator.train()\n",
    "        \n",
    "        if plot_iter % PLOT_FREQ == 0:\n",
    "            fig = plt.figure(figsize=(8, 6), dpi=80)\n",
    "            ax = fig.add_subplot()\n",
    "            ax.plot(g_losses, label='G losses')\n",
    "            ax.plot(d_losses, label='D losses')\n",
    "            ax.legend()\n",
    "            fig.savefig('D&G.png')\n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            \n",
    "        gen_iter += 1\n",
    "        plot_iter += 1\n",
    "    \n",
    "    print('Saving...')\n",
    "    save('checkpoint', epoch_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
