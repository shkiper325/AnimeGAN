{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Failed to import tensorflow.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tensorpack import dataflow\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "\n",
    "if USE_CUDA:\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print('Can\\'t find DATA_PATH:', DATA_PATH) \n",
    "    quit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = len(os.listdir(DATA_PATH))\n",
    "if DATASET_SIZE == 0:\n",
    "    print('No dataset found')\n",
    "    quit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_iter():\n",
    "    filenames = os.listdir(DATA_PATH)\n",
    "    \n",
    "    while True:\n",
    "        random.shuffle(filenames)\n",
    "        \n",
    "        for fn in filenames:\n",
    "            yield os.path.join(DATA_PATH, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIDE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    image = cv2.resize(image, (IMAGE_SIDE, IMAGE_SIDE))\n",
    "    \n",
    "    image = np.swapaxes(image, 2, 0)\n",
    "    \n",
    "    image = ((image / 255.) - .5) * 2\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_iter = dataflow.MapData(path_iter(), func=prepare_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIOR_DIM = 100\n",
    "\n",
    "ngf = 64\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(PRIOR_DIM, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            #nn.BatchNorm2d(ngf * 8),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            #nn.BatchNorm2d(ngf * 4),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            #nn.BatchNorm2d(ngf * 2),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            #nn.BatchNorm2d(ngf),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.cuda()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (-1, PRIOR_DIM, 1, 1))\n",
    "        \n",
    "        x = self.main(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = 64\n",
    "CLIP = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #nn.BatchNorm2d(ndf),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #nn.BatchNorm2d(ndf * 2),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #nn.BatchNorm2d(ndf * 4),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #nn.BatchNorm2d(ndf * 8),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        \n",
    "        return x.view((-1, 1))\n",
    "    \n",
    "    def clip(self):\n",
    "        self.main[0].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[2].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[4].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[6].weight.data.clamp_(min=-CLIP, max=CLIP)\n",
    "        self.main[8].weight.data.clamp_(min=-CLIP, max=CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_STD = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) in [nn.Conv2d, nn.Linear, nn.ConvTranspose2d]:\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0, std=INIT_STD)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.normal_(m.bias.data, mean=0, std=INIT_STD)\n",
    "    elif type(m) in [nn.BatchNorm2d, nn.LeakyReLU, nn.ReLU, nn.Sequential, nn.Tanh]:\n",
    "        return\n",
    "    else:\n",
    "        print('Couldn\\'t init wieghts of layer with type:', type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Couldn't init wieghts of layer with type: <class '__main__.G'>\nCouldn't init wieghts of layer with type: <class 'torch.nn.modules.activation.Sigmoid'>\nCouldn't init wieghts of layer with type: <class '__main__.D'>\n"
     ]
    }
   ],
   "source": [
    "generator = G()\n",
    "discriminator = D()\n",
    "\n",
    "generator.apply(init_weights)\n",
    "discriminator.apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optim = optim.RMSprop(generator.parameters(), lr = lr)\n",
    "D_optim = optim.RMSprop(discriminator.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior():\n",
    "    return np.random.multivariate_normal(np.zeros(PRIOR_DIM), np.identity(PRIOR_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_COUNT = 200000\n",
    "BATCH_SIZE = 32\n",
    "BATCH_DIVISOR = 1\n",
    "DISCRIMINATOR_LEARNING_REPEATS = 5\n",
    "\n",
    "MINIBATCH_SIZE = BATCH_SIZE // BATCH_DIVISOR\n",
    "EPOCH_LEN = int(DATASET_SIZE / (BATCH_SIZE * (DISCRIMINATOR_LEARNING_REPEATS + 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_minibatch():\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for image in image_iter:\n",
    "        ret.append(image)\n",
    "        \n",
    "        i += 1\n",
    "        if i == MINIBATCH_SIZE:\n",
    "            break\n",
    "    \n",
    "    return np.stack(ret, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fn=None):\n",
    "    if fn is None:\n",
    "        fn = 'checkpoint'\n",
    "\n",
    "    torch.save({\n",
    "        'gen': generator.state_dict(),\n",
    "        'dis': discriminator.state_dict(),\n",
    "        'g_opt': G_optim.state_dict(),\n",
    "        'd_opt': D_optim.state_dict()\n",
    "    }, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fn):\n",
    "    if fn is None:\n",
    "        fn = 'checkpoint'\n",
    "    state = torch.load(fn)\n",
    "\n",
    "    generator.load_state_dict(state['gen'])\n",
    "    discriminator.load_state_dict(state['dis'])\n",
    "    G_optim.load_state_dict(state['g_opt'])\n",
    "    D_optim.load_state_dict(state['d_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-376c6e2877d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msample_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_DIVISOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_data_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMINIBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists('generated'):\n",
    "    os.mkdir('generated')\n",
    "\n",
    "load('checkpoint')\n",
    "\n",
    "for epoch_num in range(EPOCH_COUNT):\n",
    "    print('===============================')\n",
    "    print('Epoch', epoch_num, 'started!')\n",
    "    print('===============================')\n",
    "\n",
    "    print('Saving...')\n",
    "    save('checkpoint')\n",
    "    \n",
    "    for t in range(EPOCH_LEN):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        print('t:', t)\n",
    "        \n",
    "        generator.eval()\n",
    "        discriminator.train()\n",
    "        \n",
    "        for k in range(DISCRIMINATOR_LEARNING_REPEATS):\n",
    "            D_optim.zero_grad()\n",
    "\n",
    "            for sample_num in range(BATCH_DIVISOR):\n",
    "                data = FloatTensor(get_data_minibatch())\n",
    "                p = FloatTensor(np.stack([prior() for i in range(MINIBATCH_SIZE)], axis=0))\n",
    "\n",
    "                D_of_x = discriminator(data)\n",
    "                D_of_G_of_z = discriminator(generator(p))\n",
    "\n",
    "                loss = D_of_x - D_of_G_of_z\n",
    "                loss = torch.mean(loss, dim = 0)\n",
    "                loss = -loss\n",
    "                loss = loss / BATCH_DIVISOR\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                print('D loss:', loss.detach().cpu().numpy()[0])\n",
    "                \n",
    "            D_optim.step()\n",
    "            \n",
    "            discriminator.clip()\n",
    "            \n",
    "        #=========================================\n",
    "        \n",
    "        discriminator.eval()\n",
    "        generator.train()\n",
    "        \n",
    "        G_optim.zero_grad()\n",
    "\n",
    "        for sample_num in range(BATCH_DIVISOR):\n",
    "            p = FloatTensor(np.stack([prior() for i in range(MINIBATCH_SIZE)], axis=0))\n",
    "\n",
    "            D_of_G_of_z = discriminator(generator(p))\n",
    "\n",
    "            loss = -D_of_G_of_z\n",
    "            loss = torch.mean(loss, dim = 0)\n",
    "            loss = loss / BATCH_DIVISOR\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            print('G loss:', loss.detach().cpu().numpy()[0])\n",
    "\n",
    "        G_optim.step()\n",
    "        \n",
    "        generator.eval()        \n",
    "        image = (generator(FloatTensor(np.expand_dims(prior(), 0))).detach().cpu().numpy()[0] + 1) / 2\n",
    "        image = (np.swapaxes(image, 0, 2) * 255).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join('generated', str(t) + '.jpg'), image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd0e6c42a4d7be7ea9822729b3e92badb8de8e6fc64487e4f5a7cb7289cf12b6145",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}